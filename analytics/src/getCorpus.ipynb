{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = MySQLdb.connect(user=\"root\", passwd=\"root\",\n",
    "                               host=\"d2_db\", db=\"mysql\", use_unicode=True, charset=\"utf8mb4\")\n",
    "\n",
    "cmd = 'echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
    "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
    "                           shell=True).communicate()[0]).decode('utf-8')\n",
    "m = MeCab.Tagger(\"-d {0} -Owakati\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to = re.compile(\"@[0-9a-zA-Z_]+ \")\n",
    "url = re.compile(\"https?://[0-9a-zA-Z-._~?&=/]+\")\n",
    "\n",
    "def process(tweet):\n",
    "    if tweet[:3] == \"RT \":  # リツイート\n",
    "        return \"\"\n",
    "    tweet = reply_to.sub(\"\", tweet)\n",
    "    tweet = url.sub(\"\", tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM d2.tweet\", con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"tweet.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1327571776398757890</td>\n",
       "      <td>2020-11-14 11:19:11</td>\n",
       "      <td>リュウケンテリー相手にするのめっちゃ好きなんやけどスマブラーの間でテリーが割とガチ目に嫌われ...</td>\n",
       "      <td>1574636726</td>\n",
       "      <td>{\"created_at\": \"Sat Nov 14 11:19:11 +0000 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1327571898671144961</td>\n",
       "      <td>2020-11-14 11:19:40</td>\n",
       "      <td>みんなからの匿名質問を募集中！\\n\\nこんな質問に答えてるよ\\n● 夏休みはなにしてますか？...</td>\n",
       "      <td>986542263273644033</td>\n",
       "      <td>{\"created_at\": \"Sat Nov 14 11:19:40 +0000 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1327571906619314180</td>\n",
       "      <td>2020-11-14 11:19:42</td>\n",
       "      <td>葛飾区には実質上「常磐線」の駅が全く存在しなくて「JR・千代田直通線」の駅だけが存在する感じ...</td>\n",
       "      <td>1104667162940104704</td>\n",
       "      <td>{\"created_at\": \"Sat Nov 14 11:19:42 +0000 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1327571965138276352</td>\n",
       "      <td>2020-11-14 11:19:56</td>\n",
       "      <td>RT @kurosaurus: ホントだ！\\nSeventeenの表紙ヤバいな…\\n\\nなん...</td>\n",
       "      <td>2532059880</td>\n",
       "      <td>{\"created_at\": \"Sat Nov 14 11:19:56 +0000 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1327571975590449152</td>\n",
       "      <td>2020-11-14 11:19:58</td>\n",
       "      <td>テリーめちゃくちゃ良いキャラやと思うんやけどな（※個人の意見です）</td>\n",
       "      <td>1574636726</td>\n",
       "      <td>{\"created_at\": \"Sat Nov 14 11:19:58 +0000 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171718</th>\n",
       "      <td>1353730962778058755</td>\n",
       "      <td>2021-01-25 15:46:27</td>\n",
       "      <td>RT @ikedanob: 感染研の月報は混乱している。メインのページでは無理やりプラスの超...</td>\n",
       "      <td>705015290342432768</td>\n",
       "      <td>{\"created_at\": \"Mon Jan 25 15:46:27 +0000 2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171719</th>\n",
       "      <td>1353730967786012672</td>\n",
       "      <td>2021-01-25 15:46:28</td>\n",
       "      <td>明日試験やし流石に寝るか、今日とて長話してたら想定外に遅くなった。</td>\n",
       "      <td>2833688750</td>\n",
       "      <td>{\"created_at\": \"Mon Jan 25 15:46:28 +0000 2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171720</th>\n",
       "      <td>1353730971690954752</td>\n",
       "      <td>2021-01-25 15:46:29</td>\n",
       "      <td>RT @ikedanob: 「超過死亡とかよくわからん数字でごまかすな。コロナ死者は増えてる...</td>\n",
       "      <td>705015290342432768</td>\n",
       "      <td>{\"created_at\": \"Mon Jan 25 15:46:29 +0000 2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171721</th>\n",
       "      <td>1353731412143206400</td>\n",
       "      <td>2021-01-25 15:48:14</td>\n",
       "      <td>あなたたちマスコミの扇動報道とそれによる過剰な感染対策の割を食ってる https://t.c...</td>\n",
       "      <td>705015290342432768</td>\n",
       "      <td>{\"created_at\": \"Mon Jan 25 15:48:14 +0000 2021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171722</th>\n",
       "      <td>1353731421873946624</td>\n",
       "      <td>2021-01-25 15:48:16</td>\n",
       "      <td>(70) ゴミだらけ！釣り人が集まる磯の海底を綺麗にしたらバイキンに出会った！ - YouT...</td>\n",
       "      <td>1019569328</td>\n",
       "      <td>{\"created_at\": \"Mon Jan 25 15:48:16 +0000 2021...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id          created_at  \\\n",
       "0       1327571776398757890 2020-11-14 11:19:11   \n",
       "1       1327571898671144961 2020-11-14 11:19:40   \n",
       "2       1327571906619314180 2020-11-14 11:19:42   \n",
       "3       1327571965138276352 2020-11-14 11:19:56   \n",
       "4       1327571975590449152 2020-11-14 11:19:58   \n",
       "...                     ...                 ...   \n",
       "171718  1353730962778058755 2021-01-25 15:46:27   \n",
       "171719  1353730967786012672 2021-01-25 15:46:28   \n",
       "171720  1353730971690954752 2021-01-25 15:46:29   \n",
       "171721  1353731412143206400 2021-01-25 15:48:14   \n",
       "171722  1353731421873946624 2021-01-25 15:48:16   \n",
       "\n",
       "                                                     text  \\\n",
       "0       リュウケンテリー相手にするのめっちゃ好きなんやけどスマブラーの間でテリーが割とガチ目に嫌われ...   \n",
       "1       みんなからの匿名質問を募集中！\\n\\nこんな質問に答えてるよ\\n● 夏休みはなにしてますか？...   \n",
       "2       葛飾区には実質上「常磐線」の駅が全く存在しなくて「JR・千代田直通線」の駅だけが存在する感じ...   \n",
       "3       RT @kurosaurus: ホントだ！\\nSeventeenの表紙ヤバいな…\\n\\nなん...   \n",
       "4                       テリーめちゃくちゃ良いキャラやと思うんやけどな（※個人の意見です）   \n",
       "...                                                   ...   \n",
       "171718  RT @ikedanob: 感染研の月報は混乱している。メインのページでは無理やりプラスの超...   \n",
       "171719                  明日試験やし流石に寝るか、今日とて長話してたら想定外に遅くなった。   \n",
       "171720  RT @ikedanob: 「超過死亡とかよくわからん数字でごまかすな。コロナ死者は増えてる...   \n",
       "171721  あなたたちマスコミの扇動報道とそれによる過剰な感染対策の割を食ってる https://t.c...   \n",
       "171722  (70) ゴミだらけ！釣り人が集まる磯の海底を綺麗にしたらバイキンに出会った！ - YouT...   \n",
       "\n",
       "                    user_id                                         tweet_json  \n",
       "0                1574636726  {\"created_at\": \"Sat Nov 14 11:19:11 +0000 2020...  \n",
       "1        986542263273644033  {\"created_at\": \"Sat Nov 14 11:19:40 +0000 2020...  \n",
       "2       1104667162940104704  {\"created_at\": \"Sat Nov 14 11:19:42 +0000 2020...  \n",
       "3                2532059880  {\"created_at\": \"Sat Nov 14 11:19:56 +0000 2020...  \n",
       "4                1574636726  {\"created_at\": \"Sat Nov 14 11:19:58 +0000 2020...  \n",
       "...                     ...                                                ...  \n",
       "171718   705015290342432768  {\"created_at\": \"Mon Jan 25 15:46:27 +0000 2021...  \n",
       "171719           2833688750  {\"created_at\": \"Mon Jan 25 15:46:28 +0000 2021...  \n",
       "171720   705015290342432768  {\"created_at\": \"Mon Jan 25 15:46:29 +0000 2021...  \n",
       "171721   705015290342432768  {\"created_at\": \"Mon Jan 25 15:48:14 +0000 2021...  \n",
       "171722           1019569328  {\"created_at\": \"Mon Jan 25 15:48:16 +0000 2021...  \n",
       "\n",
       "[171723 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iblank = re.compile(\"^[\\s\\t]*\\n$\")\n",
    "\n",
    "# https://crimnut.hateblo.jp/entry/2018/08/25/202253からhan2zen,zen2hanをコピーさせていただきました\n",
    "ASCII_ZENKAKU_CHARS = (\n",
    "    u'ａ', u'ｂ', u'ｃ', u'ｄ', u'ｅ', u'ｆ', u'ｇ', u'ｈ', u'ｉ', u'ｊ', u'ｋ',\n",
    "    u'ｌ', u'ｍ', u'ｎ', u'ｏ', u'ｐ', u'ｑ', u'ｒ', u'ｓ', u'ｔ', u'ｕ', u'ｖ',\n",
    "    u'ｗ', u'ｘ', u'ｙ', u'ｚ',\n",
    "    u'Ａ', u'Ｂ', u'Ｃ', u'Ｄ', u'Ｅ', u'Ｆ', u'Ｇ', u'Ｈ', u'Ｉ', u'Ｊ', u'Ｋ',\n",
    "    u'Ｌ', u'Ｍ', u'Ｎ', u'Ｏ', u'Ｐ', u'Ｑ', u'Ｒ', u'Ｓ', u'Ｔ', u'Ｕ', u'Ｖ',\n",
    "    u'Ｗ', u'Ｘ', u'Ｙ', u'Ｚ',\n",
    "    u'！', u'”', u'＃', u'＄', u'％', u'＆', u'’', u'（', u'）', u'＊', u'＋',\n",
    "    u'，', u'－', u'．', u'／', u'：', u'；', u'＜', u'＝', u'＞', u'？', u'＠',\n",
    "    u'［', u'￥', u'］', u'＾', u'＿', u'‘', u'｛', u'｜', u'｝', u'～', u'　'\n",
    ")\n",
    "\n",
    "ASCII_HANKAKU_CHARS = (\n",
    "    u'a', u'b', u'c', u'd', u'e', u'f', u'g', u'h', u'i', u'j', u'k',\n",
    "    u'l', u'm', u'n', u'o', u'p', u'q', u'r', u's', u't', u'u', u'v',\n",
    "    u'w', u'x', u'y', u'z',\n",
    "    u'A', u'B', u'C', u'D', u'E', u'F', u'G', u'H', u'I', u'J', u'K',\n",
    "    u'L', u'M', u'N', u'O', u'P', u'Q', u'R', u'S', u'T', u'U', u'V',\n",
    "    u'W', u'X', u'Y', u'Z',\n",
    "    u'!', u'\"', u'#', u'$', u'%', u'&', u'\\'', u'(', u')', u'*', u'+',\n",
    "    u',', u'-', u'.', u'/', u':', u';', u'<', u'=', u'>', u'?', u'@',\n",
    "    u'[', u\"¥\", u']', u'^', u'_', u'`', u'{', u'|', u'}', u'~', u' '\n",
    ")\n",
    "\n",
    "KANA_ZENKAKU_CHARS = (\n",
    "    u'ア', u'イ', u'ウ', u'エ', u'オ', u'カ', u'キ', u'ク', u'ケ', u'コ',\n",
    "    u'サ', u'シ', u'ス', u'セ', u'ソ', u'タ', u'チ', u'ツ', u'テ', u'ト',\n",
    "    u'ナ', u'ニ', u'ヌ', u'ネ', u'ノ', u'ハ', u'ヒ', u'フ', u'ヘ', u'ホ',\n",
    "    u'マ', u'ミ', u'ム', u'メ', u'モ', u'ヤ', u'ユ', u'ヨ',\n",
    "    u'ラ', u'リ', u'ル', u'レ', u'ロ', u'ワ', u'ヲ', u'ン',\n",
    "    u'ァ', u'ィ', u'ゥ', u'ェ', u'ォ', u'ッ', u'ャ', u'ュ', u'ョ',\n",
    "    u'。', u'、', u'・', u'゛', u'゜', u'「', u'」', u'ー'\n",
    ")\n",
    "\n",
    "KANA_HANKAKU_CHARS = (\n",
    "    u'ｱ', u'ｲ', u'ｳ', u'ｴ', u'ｵ', u'ｶ', u'ｷ', u'ｸ', u'ｹ', u'ｺ',\n",
    "    u'ｻ', u'ｼ', u'ｽ', u'ｾ', u'ｿ', u'ﾀ', u'ﾁ', u'ﾂ', u'ﾃ', u'ﾄ',\n",
    "    u'ﾅ', u'ﾆ', u'ﾇ', u'ﾈ', u'ﾉ', u'ﾊ', u'ﾋ', u'ﾌ', u'ﾍ', u'ﾎ',\n",
    "    u'ﾏ', u'ﾐ', u'ﾑ', u'ﾒ', u'ﾓ', u'ﾔ', u'ﾕ', u'ﾖ',\n",
    "    u'ﾗ', u'ﾘ', u'ﾙ', u'ﾚ', u'ﾛ', u'ﾜ', u'ｦ', u'ﾝ',\n",
    "    u'ｧ', u'ｨ', u'ｩ', u'ｪ', u'ｫ', u'ｯ', u'ｬ', u'ｭ', u'ｮ',\n",
    "    u'｡', u'､', u'･', u'ﾞ', u'ﾟ', u'｢', u'｣', u'ｰ'\n",
    ")\n",
    "\n",
    "DIGIT_ZENKAKU_CHARS = (\n",
    "    u'０', u'１', u'２', u'３', u'４', u'５', u'６', u'７', u'８', u'９'\n",
    ")\n",
    "\n",
    "DIGIT_HANKAKU_CHARS = (\n",
    "    u'0', u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9'\n",
    ")\n",
    "\n",
    "KANA_TEN_MAP = (\n",
    "    (u'ガ', u'ｶ'), (u'ギ', u'ｷ'), (u'グ', u'ｸ'), (u'ゲ', u'ｹ'), (u'ゴ', u'ｺ'),\n",
    "    (u'ザ', u'ｻ'), (u'ジ', u'ｼ'), (u'ズ', u'ｽ'), (u'ゼ', u'ｾ'), (u'ゾ', u'ｿ'),\n",
    "    (u'ダ', u'ﾀ'), (u'ヂ', u'ﾁ'), (u'ヅ', u'ﾂ'), (u'デ', u'ﾃ'), (u'ド', u'ﾄ'),\n",
    "    (u'バ', u'ﾊ'), (u'ビ', u'ﾋ'), (u'ブ', u'ﾌ'), (u'ベ', u'ﾍ'), (u'ボ', u'ﾎ'),\n",
    "    (u'ヴ', u'ｳ')\n",
    ")\n",
    "\n",
    "KANA_MARU_MAP = (\n",
    "    (u'パ', u'ﾊ'), (u'ピ', u'ﾋ'), (u'プ', u'ﾌ'), (u'ペ', u'ﾍ'), (u'ポ', u'ﾎ')\n",
    ")\n",
    "\n",
    "\n",
    "ascii_zh_table = {}\n",
    "ascii_hz_table = {}\n",
    "kana_zh_table = {}\n",
    "kana_hz_table = {}\n",
    "digit_zh_table = {}\n",
    "digit_hz_table = {}\n",
    "\n",
    "for (az, ah) in zip(ASCII_ZENKAKU_CHARS, ASCII_HANKAKU_CHARS):\n",
    "    ascii_zh_table[az] = ah\n",
    "    ascii_hz_table[ah] = az\n",
    "\n",
    "for (kz, kh) in zip(KANA_ZENKAKU_CHARS, KANA_HANKAKU_CHARS):\n",
    "    kana_zh_table[kz] = kh\n",
    "    kana_hz_table[kh] = kz\n",
    "\n",
    "for (dz, dh) in zip(DIGIT_ZENKAKU_CHARS, DIGIT_HANKAKU_CHARS):\n",
    "    digit_zh_table[dz] = dh\n",
    "    digit_hz_table[dh] = dz\n",
    "\n",
    "kana_ten_zh_table = {}\n",
    "kana_ten_hz_table = {}\n",
    "kana_maru_zh_table = {}\n",
    "kana_maru_hz_table = {}\n",
    "for (ktz, kth) in KANA_TEN_MAP:\n",
    "    kana_ten_zh_table[ktz] = kth\n",
    "    kana_ten_hz_table[kth] = ktz\n",
    "\n",
    "for (kmz, kmh) in KANA_MARU_MAP:\n",
    "    kana_maru_zh_table[kmz] = kmh\n",
    "    kana_maru_hz_table[kmh] = kmz\n",
    "\n",
    "del ASCII_ZENKAKU_CHARS, ASCII_HANKAKU_CHARS, \\\n",
    "    KANA_ZENKAKU_CHARS, KANA_HANKAKU_CHARS,\\\n",
    "    DIGIT_ZENKAKU_CHARS, DIGIT_HANKAKU_CHARS,\\\n",
    "    KANA_TEN_MAP, KANA_MARU_MAP\n",
    "\n",
    "kakko_zh_table = {\n",
    "    u'｟': u'⦅', u'｠': u'⦆',\n",
    "    u'『': u'｢', u'』': u'｣',\n",
    "    u'〚': u'⟦', u'〛': u'⟧',\n",
    "    u'〔': u'❲', u'〕': u'❳',\n",
    "    u'〘': u'⟬', u'〙': u'⟭',\n",
    "    u'《': u'⟪', u'》': u'⟫',\n",
    "    u'【': u'(', u'】': u')',\n",
    "    u'〖': u'(', u'〗': u')'\n",
    "}\n",
    "kakko_hz_table = {}\n",
    "for k, v in kakko_zh_table.items():\n",
    "    kakko_hz_table[v] = k\n",
    "\n",
    "\n",
    "def zen2han(text=\"\", ascii_=True, digit=True, kana=True, kakko=True, ignore=()):\n",
    "    result = []\n",
    "    for c in text:\n",
    "        if c in ignore:\n",
    "            result.append(c)\n",
    "        elif ascii_ and (c in ascii_zh_table):\n",
    "            result.append(ascii_zh_table[c])\n",
    "        elif digit and (c in digit_zh_table):\n",
    "            result.append(digit_zh_table[c])\n",
    "        elif kana and (c in kana_zh_table):\n",
    "            result.append(kana_zh_table[c])\n",
    "        elif kana and (c in kana_ten_zh_table):\n",
    "            result.append(kana_ten_zh_table[c] + u'ﾞ')\n",
    "        elif kana and (c in kana_maru_zh_table):\n",
    "            result.append(kana_maru_zh_table[c] + u'ﾟ')\n",
    "        elif kakko and (c in kakko_zh_table):\n",
    "            result.append(kakko_zh_table[c])\n",
    "        else:\n",
    "            result.append(c)\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "def han2zen(text, ascii_=True, digit=True, kana=True, kakko=True, ignore=()):\n",
    "    result = []\n",
    "    for i, c in enumerate(text):\n",
    "        if c == u'ﾞ' or c == u'ﾟ':\n",
    "            continue\n",
    "        elif c in ignore:\n",
    "            result.append(c)\n",
    "        elif ascii_ and (c in ascii_hz_table):\n",
    "            result.append(ascii_hz_table[c])\n",
    "        elif digit and (c in digit_hz_table):\n",
    "            result.append(digit_hz_table[c])\n",
    "        elif kana and (c in kana_ten_hz_table) and (text[i + 1] == u'ﾞ'):\n",
    "            result.append(kana_ten_hz_table[c])\n",
    "        elif kana and (c in kana_maru_hz_table) and (text[i + 1] == u'ﾟ'):\n",
    "            result.append(kana_maru_hz_table[c])\n",
    "        elif kana and (c in kana_hz_table):\n",
    "            result.append(kana_hz_table[c])\n",
    "        elif kakko and (c in kakko_hz_table):\n",
    "            result.append(kakko_hz_table[c])\n",
    "        else:\n",
    "            result.append(c)\n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to = re.compile(\"@[0-9a-zA-Z_]+ \")\n",
    "url = re.compile(\"https?://[0-9a-zA-Z-._~?&=/]+\")\n",
    "\n",
    "def process(tweet):\n",
    "    if tweet[:2]==\"RT\":\n",
    "        return \"\"\n",
    "    try:\n",
    "        tweet = reply_to.sub(\"@\", tweet)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = url.sub(\"\", tweet)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = re.sub(\"[！!]+\", \"!\", tweet)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = re.sub(\"[？?]+\", \"?\", tweet)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = han2zen(tweet, ascii_=False, digit=False,\n",
    "                        kakko=False, kana=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = zen2han(tweet, kana=False)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = re.sub(\"\\d+\", \"0\", tweet)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = re.sub(\"\\n+\",\"\\n\",tweet)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        tweet = re.sub(\"\\s+\",\" \",tweet)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        tweet = re.sub(\"[^ぁ-んァ-ヶー一-龠\\x00-\\x7F]+\",\"\",tweet)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1503ca13533446609eb707b22b1b7063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/171723 [00:03<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].progress_apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490339ffd8d044f9b1fae24ce768e73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/171723 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chars = set()\n",
    "for text in tqdm(df.text):\n",
    "    chars = chars.union(set([c for c in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(list(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f4b14d506045409e2571693e761bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"real_data.txt\",\"w\") as fp:\n",
    "    for text in tqdm(set(df.text)):\n",
    "        if text==\"\":\n",
    "            continue\n",
    "        text = text[:20]\n",
    "        text+=\"_\"*(20-len(text))\n",
    "        text = le.transform([c for c in text])\n",
    "        text=\" \".join([str(i) for i in text])\n",
    "        fp.write(text)\n",
    "        fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"le.pkl\",\"wb\") as fp:\n",
    "    pickle.dump(le,fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
